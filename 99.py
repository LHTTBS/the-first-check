import pandas as pd
import json
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer, BertModel
from sklearn.metrics import accuracy_score, f1_score, classification_report
import numpy as np
from typing import Dict, List, Tuple
import time
from sklearn.utils.class_weight import compute_class_weight
import sys

# è®¾ç½®æ¨¡å‹è·¯å¾„
model_path = "C:/Users/LHTBS/Desktop/check919/models/chinese-roberta-wwm-ext"

class TextDataset(Dataset):
    def __init__(self, dataframe, tokenizer, max_length=256):
        self.data = dataframe
        self.tokenizer = tokenizer
        self.max_length = max_length
        
        # æ ‡ç­¾æ˜ å°„
        self.stance_map = {'Against': 0, 'Neither': 1, 'Favor': 2}
        self.fairness_map = {'Tinted': 0, 'Fairness': 1}
        self.harmfulness_map = {'Harmful': 0, 'Unharmful': 1}
        
        # Intentæ˜¯å¤šæ ‡ç­¾åˆ†ç±»
        self.intent_labels = ['Political_interest', 'Economic_interest', 
                             'Psychological_fulfillment', 'Public_interest']
        
    def __len__(self):
        return len(self.data)
    
    def encode_intent(self, intent_str):
        """å°†å¤šæ ‡ç­¾intentç¼–ç ä¸ºäºŒè¿›åˆ¶å‘é‡"""
        if pd.isna(intent_str):
            return [0] * len(self.intent_labels)
        
        intent_list = str(intent_str).split('&')
        encoding = [0] * len(self.intent_labels)
        
        for i, label in enumerate(self.intent_labels):
            if label in intent_list:
                encoding[i] = 1
                
        return encoding
    
    def __getitem__(self, idx):
        row = self.data.iloc[idx]
        text = str(row['text']) if 'text' in row else "default text"
        
        # ç¼–ç æ–‡æœ¬
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        # è·å–æ ‡ç­¾ - æ·»åŠ å®¹é”™å¤„ç†
        stance = self.stance_map.get(str(row['stance']), 1)  # é»˜è®¤Neither
        fairness = self.fairness_map.get(str(row['fairness']), 0)  # é»˜è®¤Tinted
        harmfulness = self.harmfulness_map.get(str(row['harmfulness']), 0)  # é»˜è®¤Harmful
        intent = self.encode_intent(row['intent'])
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'stance': torch.tensor(stance, dtype=torch.long),
            'intent': torch.tensor(intent, dtype=torch.float),
            'fairness': torch.tensor(fairness, dtype=torch.long),
            'harmfulness': torch.tensor(harmfulness, dtype=torch.long)
        }

class MultiScaleFeatureExtractor(nn.Module):
    """å¤šå°ºåº¦ç‰¹å¾æå–å™¨"""
    def __init__(self, input_dim: int = 768, output_dim: int = 256, dropout: float = 0.1):
        super(MultiScaleFeatureExtractor, self).__init__()
        
        # å¤šå°ºåº¦å·ç§¯å±‚
        self.conv1 = nn.Conv1d(input_dim, 128, kernel_size=2, padding=1)  # å±€éƒ¨ç‰¹å¾
        self.conv2 = nn.Conv1d(input_dim, 128, kernel_size=3, padding=1)  # ä¸­ç­‰ç‰¹å¾
        self.conv3 = nn.Conv1d(input_dim, 128, kernel_size=5, padding=2)  # å…¨å±€ç‰¹å¾
        
        # ç‰¹å¾èåˆ
        self.fusion = nn.Sequential(
            nn.Linear(384, 512),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(512, output_dim),
            nn.GELU(),
            nn.Dropout(dropout)
        )
        
        self.layer_norm = nn.LayerNorm(output_dim)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # x: [batch_size, seq_len, hidden_size] -> è½¬ç½®ä¸º [batch_size, hidden_size, seq_len]
        x = x.transpose(1, 2)
        
        # å¤šå°ºåº¦å·ç§¯
        local_feat = F.relu(self.conv1(x))  # [batch_size, 128, seq_len]
        medium_feat = F.relu(self.conv2(x)) # [batch_size, 128, seq_len]
        global_feat = F.relu(self.conv3(x)) # [batch_size, 128, seq_len]
        
        # å…¨å±€å¹³å‡æ± åŒ–
        local_pool = F.adaptive_avg_pool1d(local_feat, 1).squeeze(-1)  # [batch_size, 128]
        medium_pool = F.adaptive_avg_pool1d(medium_feat, 1).squeeze(-1) # [batch_size, 128]
        global_pool = F.adaptive_avg_pool1d(global_feat, 1).squeeze(-1) # [batch_size, 128]
        
        # æ‹¼æ¥å¤šå°ºåº¦ç‰¹å¾
        multi_scale_features = torch.cat([local_pool, medium_pool, global_pool], dim=1)  # [batch_size, 384]
        
        # ç‰¹å¾èåˆ
        fused_features = self.fusion(multi_scale_features)  # [batch_size, output_dim]
        fused_features = self.layer_norm(fused_features)
        
        return fused_features

class DifferentiatedFeatureExtractor(nn.Module):
    """å·®å¼‚åŒ–å¤šè§†è§’ç‰¹å¾æå–å™¨ - æ¯ä¸ªè§†è§’æœ‰ä¸åŒçš„ç½‘ç»œç»“æ„"""
    def __init__(self, perspective_type: str, input_dim: int = 768, output_dim: int = 256, dropout: float = 0.1):
        super(DifferentiatedFeatureExtractor, self).__init__()
        self.perspective_type = perspective_type
        
        if perspective_type == "belief":
            # ä¿¡å¿µè§†è§’ï¼šæ›´æ·±ç½‘ç»œï¼Œå…³æ³¨æ·±å±‚æ¬¡ç†è§£
            self.feature_net = nn.Sequential(
                nn.Linear(input_dim, 512),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(512, 384),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(384, output_dim),
                nn.LayerNorm(output_dim)
            )
        elif perspective_type == "desire":
            # æ¬²æœ›è§†è§’ï¼šä¸­ç­‰æ·±åº¦ï¼Œå…³æ³¨åŠ¨æœº
            self.feature_net = nn.Sequential(
                nn.Linear(input_dim, 448),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(448, output_dim),
                nn.LayerNorm(output_dim)
            )
        else:  # plan
            # è®¡åˆ’è§†è§’ï¼šæ›´æµ…ç½‘ç»œï¼Œå…³æ³¨è¡ŒåŠ¨å±‚é¢
            self.feature_net = nn.Sequential(
                nn.Linear(input_dim, 320),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(320, output_dim),
                nn.LayerNorm(output_dim)
            )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.feature_net(x)

class EnhancedIntentClassifier(nn.Module):
    """å¢å¼ºçš„æ„å›¾åˆ†ç±»å™¨ - ä¸“é—¨å¤„ç†å¤šæ ‡ç­¾åˆ†ç±»"""
    def __init__(self, feature_dim: int = 256, num_intents: int = 4, dropout: float = 0.2):
        super(EnhancedIntentClassifier, self).__init__()
        
        # æ›´æ·±çš„ç½‘ç»œç»“æ„æ¥å¤„ç†å¤šæ ‡ç­¾å…³ç³»
        self.intent_net = nn.Sequential(
            nn.Linear(feature_dim, 512),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(512, 256),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(256, 128),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(128, num_intents)
        )
        
        # æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰æ ‡ç­¾é—´çš„å…³ç³»
        self.attention = nn.MultiheadAttention(
            embed_dim=num_intents, 
            num_heads=2,
            dropout=dropout,
            batch_first=True
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # åŸºç¡€æ„å›¾åˆ†ç±»
        intent_logits = self.intent_net(x)
        
        # ä½¿ç”¨è‡ªæ³¨æ„åŠ›æ•æ‰æ ‡ç­¾é—´å…³ç³»
        intent_logits_reshaped = intent_logits.unsqueeze(1)  # [batch_size, 1, num_intents]
        attended_logits, _ = self.attention(
            intent_logits_reshaped, 
            intent_logits_reshaped, 
            intent_logits_reshaped
        )
        attended_logits = attended_logits.squeeze(1)
        
        return attended_logits

class GatedIntentAggregator(nn.Module):
    """é—¨æ§æ„å›¾èšåˆå™¨"""
    def __init__(self, feature_dim: int = 256, num_intents: int = 4, dropout: float = 0.1):
        super(GatedIntentAggregator, self).__init__()
        
        # é—¨æ§æœºåˆ¶ - å­¦ä¹ æ¯ä¸ªè§†è§’çš„é‡è¦æ€§æƒé‡
        self.gate_network = nn.Sequential(
            nn.Linear(feature_dim * 3, feature_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(feature_dim, 3),  # 3ä¸ªè§†è§’çš„æƒé‡
            nn.Softmax(dim=1)
        )
        
        # ç‰¹å¾èåˆç½‘ç»œ
        self.fusion_network = nn.Sequential(
            nn.Linear(feature_dim * 3, feature_dim * 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(feature_dim * 2, feature_dim),
            nn.LayerNorm(feature_dim)
        )
        
        # ä½¿ç”¨å¢å¼ºçš„æ„å›¾åˆ†ç±»å™¨
        self.intent_classifier = EnhancedIntentClassifier(feature_dim, num_intents, dropout)
        
    def forward(self, belief_features: torch.Tensor, desire_features: torch.Tensor, 
                plan_features: torch.Tensor) -> Dict[str, torch.Tensor]:
        
        batch_size = belief_features.size(0)
        
        # æ‹¼æ¥æ‰€æœ‰è§†è§’ç‰¹å¾
        concatenated = torch.cat([belief_features, desire_features, plan_features], dim=1)
        
        # è®¡ç®—é—¨æ§æƒé‡
        gate_weights = self.gate_network(concatenated)  # [batch_size, 3]
        
        # åº”ç”¨é—¨æ§æƒé‡çš„åŠ æƒèåˆ
        weighted_belief = belief_features * gate_weights[:, 0:1]
        weighted_desire = desire_features * gate_weights[:, 1:2]
        weighted_plan = plan_features * gate_weights[:, 2:3]
        
        # æ‹¼æ¥åŠ æƒç‰¹å¾
        weighted_concatenated = torch.cat([weighted_belief, weighted_desire, weighted_plan], dim=1)
        
        # ç‰¹å¾èåˆ
        fused_features = self.fusion_network(weighted_concatenated)
        
        # æ„å›¾åˆ†ç±»
        intent_logits = self.intent_classifier(fused_features)
        
        return {
            'intent_logits': intent_logits,
            'fused_features': fused_features,
            'gate_weights': gate_weights  # è¿”å›é—¨æ§æƒé‡ç”¨äºåˆ†æ
        }

class EnhancedDMINTModel(nn.Module):
    """å¢å¼ºç‰ˆDMINTæ¨¡å‹ - ä¸“é—¨ä¼˜åŒ–å¤šæ ‡ç­¾åˆ†ç±»"""
    def __init__(self, bert_model, hidden_size: int = 768, feature_dim: int = 256, dropout: float = 0.3):
        super(EnhancedDMINTModel, self).__init__()
        
        self.bert = bert_model
        
        # å¤šå°ºåº¦ç‰¹å¾æå–å™¨ï¼ˆç”¨äºåºåˆ—ç‰¹å¾ï¼‰
        self.multi_scale_extractor = MultiScaleFeatureExtractor(hidden_size, feature_dim, dropout)
        
        # ä¸‰ä¸ªå·®å¼‚åŒ–çš„è§†è§’ç‰¹å¾æå–å™¨ï¼ˆç”¨äºCLSç‰¹å¾ï¼‰
        self.belief_extractor = DifferentiatedFeatureExtractor("belief", hidden_size, feature_dim, dropout)
        self.desire_extractor = DifferentiatedFeatureExtractor("desire", hidden_size, feature_dim, dropout)
        self.plan_extractor = DifferentiatedFeatureExtractor("plan", hidden_size, feature_dim, dropout)
        
        # é—¨æ§æ„å›¾èšåˆå™¨
        self.intent_aggregator = GatedIntentAggregator(feature_dim, 4, dropout)
        
        # ä»»åŠ¡ç‰¹å®šçš„åˆ†ç±»å™¨
        self.stance_classifier = nn.Sequential(
            nn.Linear(feature_dim * 2, 128),  # ä½¿ç”¨å¤šå°ºåº¦ç‰¹å¾+ä¿¡å¿µç‰¹å¾
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(128, 3)  # Against, Neither, Favor
        )
        
        self.harmfulness_classifier = nn.Sequential(
            nn.Linear(feature_dim * 2, 128),  # ä½¿ç”¨å¤šå°ºåº¦ç‰¹å¾+è®¡åˆ’ç‰¹å¾
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(128, 2)  # Harmful, Unharmful
        )
        
        self.fairness_classifier = nn.Sequential(
            nn.Linear(feature_dim, 128),  # ä½¿ç”¨èåˆç‰¹å¾
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(128, 2)  # Tinted, Fairness
        )
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> Dict[str, torch.Tensor]:
        # BERTç‰¹å¾æå– - è·å–åºåˆ—è¾“å‡ºå’ŒCLSè¾“å‡º
        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        sequence_output = bert_output.last_hidden_state  # [batch_size, seq_len, hidden_size]
        cls_features = bert_output.pooler_output  # [batch_size, hidden_size]
        
        # å¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆåŸºäºåºåˆ—è¾“å‡ºï¼‰
        multi_scale_features = self.multi_scale_extractor(sequence_output)
        
        # ä¸‰ä¸ªè§†è§’çš„ç‰¹å¾æå–ï¼ˆåŸºäºCLSç‰¹å¾ï¼‰
        belief_features = self.belief_extractor(cls_features)
        desire_features = self.desire_extractor(cls_features)
        plan_features = self.plan_extractor(cls_features)
        
        # åº”ç”¨dropout
        belief_features = self.dropout(belief_features)
        desire_features = self.dropout(desire_features)
        plan_features = self.dropout(plan_features)
        multi_scale_features = self.dropout(multi_scale_features)
        
        # é—¨æ§æ„å›¾èšåˆ
        intent_output = self.intent_aggregator(belief_features, desire_features, plan_features)
        fused_features = intent_output['fused_features']
        intent_logits = intent_output['intent_logits']
        
        # ä»»åŠ¡åˆ†ç±» - ç»“åˆå¤šå°ºåº¦ç‰¹å¾å’Œè§†è§’ç‰¹å¾
        stance_input = torch.cat([multi_scale_features, belief_features], dim=1)
        stance_logits = self.stance_classifier(stance_input)
        
        harmfulness_input = torch.cat([multi_scale_features, plan_features], dim=1)
        harmfulness_logits = self.harmfulness_classifier(harmfulness_input)
        
        fairness_logits = self.fairness_classifier(fused_features)
        
        return {
            'stance': stance_logits,
            'intent': intent_logits,
            'harmfulness': harmfulness_logits,
            'fairness': fairness_logits,
            'belief_features': belief_features,
            'desire_features': desire_features,
            'plan_features': plan_features,
            'multi_scale_features': multi_scale_features,
            'gate_weights': intent_output['gate_weights']  # è¿”å›é—¨æ§æƒé‡
        }

def compute_intent_class_weights(train_df):
    """è®¡ç®—å¤šæ ‡ç­¾åˆ†ç±»çš„ç±»åˆ«æƒé‡"""
    intent_labels = ['Political_interest', 'Economic_interest', 
                    'Psychological_fulfillment', 'Public_interest']
    
    # ç»Ÿè®¡æ¯ä¸ªæ ‡ç­¾çš„å‡ºç°æ¬¡æ•°
    label_counts = [0] * len(intent_labels)
    total_samples = len(train_df)
    
    for idx, row in train_df.iterrows():
        intent_str = str(row['intent'])
        if pd.isna(intent_str):
            continue
            
        intent_list = intent_str.split('&')
        for i, label in enumerate(intent_labels):
            if label in intent_list:
                label_counts[i] += 1
    
    # è®¡ç®—æƒé‡ï¼šæ ·æœ¬æ€»æ•° / (ç±»åˆ«æ•° * ç±»åˆ«å‡ºç°æ¬¡æ•°)
    # ä½¿ç”¨å¹³æ»‘å¤„ç†é¿å…é™¤é›¶
    weights = []
    for count in label_counts:
        if count > 0:
            weight = total_samples / (len(intent_labels) * count)
        else:
            weight = 1.0  # å¦‚æœæŸä¸ªæ ‡ç­¾æ²¡æœ‰å‡ºç°ï¼Œä½¿ç”¨é»˜è®¤æƒé‡
        weights.append(weight)
    
    print(f"Intentæ ‡ç­¾åˆ†å¸ƒ: {dict(zip(intent_labels, label_counts))}")
    print(f"Intentç±»åˆ«æƒé‡: {dict(zip(intent_labels, [f'{w:.2f}' for w in weights]))}")
    
    return torch.tensor(weights, dtype=torch.float)

def load_and_preprocess_data():
    """åŠ è½½å’Œé¢„å¤„ç†æ•°æ® - ä¿®å¤äº†CSVåˆ†éš”ç¬¦é—®é¢˜"""
    data_dir = "data/"
    
    # ä¿®å¤ï¼šç»Ÿä¸€ä½¿ç”¨é€—å·åˆ†éš”ç¬¦
    train_df = pd.read_csv(os.path.join(data_dir, "train.csv"), sep=',', header=None,
                          names=['id', 'stance', 'intent', 'fairness', 'harmfulness'])
    val_df = pd.read_csv(os.path.join(data_dir, "val.csv"), sep=',', header=None,
                        names=['id', 'stance', 'intent', 'fairness', 'harmfulness'])
    test_df = pd.read_csv(os.path.join(data_dir, "test1.csv"), sep=',', header=None,
                         names=['id', 'stance', 'intent', 'fairness', 'harmfulness'])
    
    # åŠ è½½JSONæ•°æ®å¹¶æ•´åˆæ–‡æœ¬
    def load_json_data():
        topics_path = os.path.join(data_dir, "news_topic1.json")
        docs_path = os.path.join(data_dir, "news_docs.json")
        
        topics_data = {}
        docs_data = {}
        
        if os.path.exists(topics_path):
            with open(topics_path, 'r', encoding='utf-8') as f:
                topics_data = json.load(f)
        
        if os.path.exists(docs_path):
            with open(docs_path, 'r', encoding='utf-8') as f:
                docs_data = json.load(f)
        
        return topics_data, docs_data
    
    topics_data, docs_data = load_json_data()
    
    def get_text_content(row_id):
        """ä¼˜åŒ–æ–‡æœ¬å†…å®¹è·å–"""
        str_id = str(row_id)
        topic_text = topics_data.get(str_id, "unknown topic")
        
        # å¦‚æœæœ‰æ–‡æ¡£æ•°æ®ï¼Œä½¿ç”¨æ–‡æ¡£å†…å®¹ï¼›å¦åˆ™åªä½¿ç”¨æ ‡é¢˜
        doc_content = ""
        if docs_data and str_id in docs_data:
            doc_content = docs_data.get(str_id, {}).get("content", "")
        
        # å¦‚æœå†…å®¹ä¸ºç©ºï¼Œè‡³å°‘ä½¿ç”¨æ ‡é¢˜
        if not doc_content.strip():
            return topic_text
        else:
            return f"{topic_text} {doc_content}"
    
    # ä¸ºæ•°æ®æ¡†æ·»åŠ æ–‡æœ¬åˆ—
    train_df['text'] = train_df['id'].apply(get_text_content)
    val_df['text'] = val_df['id'].apply(get_text_content)
    test_df['text'] = test_df['id'].apply(get_text_content)
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_df)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_df)}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_df)}")
    
    # æ‰“å°æ ‡ç­¾åˆ†å¸ƒ
    print("\nè®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ:")
    print(f"Stance: {train_df['stance'].value_counts().to_dict()}")
    print(f"Intentæ ·æœ¬åˆ†å¸ƒ: {train_df['intent'].value_counts().head(10).to_dict()}")
    print(f"Fairness: {train_df['fairness'].value_counts().to_dict()}")
    print(f"Harmfulness: {train_df['harmfulness'].value_counts().to_dict()}")
    
    return train_df, val_df, test_df

def safe_intent_metrics(predictions, labels):
    """å®‰å…¨åœ°è®¡ç®—å¤šæ ‡ç­¾åˆ†ç±»æŒ‡æ ‡ï¼Œå¤„ç†ç»´åº¦é—®é¢˜"""
    if len(predictions) == 0 or len(labels) == 0:
        return {
            'exact_match': 0.0,
            'macro_f1': 0.0,
            'micro_f1': 0.0,
            'per_label_f1': [0.0, 0.0, 0.0, 0.0]
        }
    
    try:
        predictions_array = np.array(predictions)
        labels_array = np.array(labels)
        
        # ç¡®ä¿æ•°ç»„æ˜¯äºŒç»´çš„
        if predictions_array.ndim == 1:
            predictions_array = predictions_array.reshape(1, -1)
            labels_array = labels_array.reshape(1, -1)
        
        # ç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡
        exact_match = np.mean(np.all(predictions_array == labels_array, axis=1))
        
        # è®¡ç®—F1åˆ†æ•°
        try:
            macro_f1 = f1_score(labels_array, predictions_array, average='macro', zero_division=0)
            micro_f1 = f1_score(labels_array, predictions_array, average='micro', zero_division=0)
            per_label_f1 = f1_score(labels_array, predictions_array, average=None, zero_division=0)
        except:
            macro_f1 = 0.0
            micro_f1 = 0.0
            per_label_f1 = [0.0] * 4
        
        return {
            'exact_match': float(exact_match),
            'macro_f1': float(macro_f1),
            'micro_f1': float(micro_f1),
            'per_label_f1': per_label_f1.tolist() if hasattr(per_label_f1, 'tolist') else per_label_f1
        }
    except Exception as e:
        print(f"è®¡ç®—intentæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        return {
            'exact_match': 0.0,
            'macro_f1': 0.0,
            'micro_f1': 0.0,
            'per_label_f1': [0.0, 0.0, 0.0, 0.0]
        }

class ImprovedDMINTTrainer:
    """æ”¹è¿›çš„è®­ç»ƒå™¨ - ä¸“é—¨ä¼˜åŒ–å¤šæ ‡ç­¾åˆ†ç±»"""
    def __init__(self, model, train_loader, val_loader, device, num_epochs=5, intent_class_weights=None):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.num_epochs = num_epochs
        
        # æŸå¤±å‡½æ•° - ä¸ºå¤šæ ‡ç­¾åˆ†ç±»ä½¿ç”¨å¸¦æƒé‡çš„BCE
        self.criterion_stance = nn.CrossEntropyLoss()
        
        # ä¸ºå¤šæ ‡ç­¾åˆ†ç±»ä½¿ç”¨å¸¦æƒé‡çš„BCEWithLogitsLoss
        if intent_class_weights is not None:
            self.criterion_intent = nn.BCEWithLogitsLoss(pos_weight=intent_class_weights.to(device))
            print(f"ä½¿ç”¨åŠ æƒçš„å¤šæ ‡ç­¾æŸå¤±å‡½æ•°ï¼Œæƒé‡: {intent_class_weights}")
        else:
            self.criterion_intent = nn.BCEWithLogitsLoss()
            
        self.criterion_harmfulness = nn.CrossEntropyLoss()
        self.criterion_fairness = nn.CrossEntropyLoss()
        
        # ä¼˜åŒ–å™¨ - ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡
        self.optimizer = torch.optim.AdamW(
            model.parameters(), 
            lr=2e-5,  # ä»1e-5å¢åŠ åˆ°2e-5
            weight_decay=0.01
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer, 
            T_0=10,
            T_mult=2
        )
        
        self.best_val_loss = float('inf')
        self.best_intent_f1 = 0.0
        self.patience = 8
        self.counter = 0
        self.start_time = time.time()
        
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        total_batches = len(self.train_loader)
        
        epoch_start_time = time.time()
        
        for batch_idx, batch in enumerate(self.train_loader):
            batch_start_time = time.time()
            
            self.optimizer.zero_grad()
            
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            stance_labels = batch['stance'].to(self.device)
            intent_labels = batch['intent'].to(self.device)
            harmfulness_labels = batch['harmfulness'].to(self.device)
            fairness_labels = batch['fairness'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(input_ids, attention_mask)
            
            # è®¡ç®—å¤šä»»åŠ¡æŸå¤±
            loss_stance = self.criterion_stance(outputs['stance'], stance_labels)
            loss_intent = self.criterion_intent(outputs['intent'], intent_labels)
            loss_harmfulness = self.criterion_harmfulness(outputs['harmfulness'], harmfulness_labels)
            loss_fairness = self.criterion_fairness(outputs['fairness'], fairness_labels)
            
            # åŠ¨æ€æƒé‡è°ƒæ•´ - ç»™å¤šæ ‡ç­¾åˆ†ç±»æ›´é«˜æƒé‡
            total_loss_batch = (loss_stance + 4.0 * loss_intent + 
                              loss_harmfulness + loss_fairness)
            total_loss_batch.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            total_loss += total_loss_batch.item()
            
            # æ¯50ä¸ªbatchæ‰“å°ä¸€æ¬¡è¿›åº¦
            if batch_idx % 10 == 0:
                progress = (batch_idx / total_batches) * 100
                batch_time = time.time() - batch_start_time
                estimated_epoch_time = (batch_time / (batch_idx + 1)) * total_batches
                remaining_time = estimated_epoch_time * (self.num_epochs - epoch + 1)
                
                print(f'  Batch {batch_idx}/{total_batches} ({progress:.1f}%), '
                      f'Loss: {total_loss_batch.item():.4f}, '
                      f'Intent Loss: {loss_intent.item():.4f}, '
                      f'Batch Time: {batch_time:.2f}s')
        
        epoch_time = time.time() - epoch_start_time
        avg_loss = total_loss / total_batches
        return avg_loss, epoch_time
    
    def validate(self):
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        total_loss = 0
        total_batches = len(self.val_loader)
        
        all_predictions = {'stance': [], 'intent': [], 'harmfulness': [], 'fairness': []}
        all_labels = {'stance': [], 'intent': [], 'harmfulness': [], 'fairness': []}
        
        with torch.no_grad():
            for batch in self.val_loader:
                # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                stance_labels = batch['stance'].to(self.device)
                intent_labels = batch['intent'].to(self.device)
                harmfulness_labels = batch['harmfulness'].to(self.device)
                fairness_labels = batch['fairness'].to(self.device)
                
                # å‰å‘ä¼ æ’­
                outputs = self.model(input_ids, attention_mask)
                
                # è®¡ç®—æŸå¤±
                loss_stance = self.criterion_stance(outputs['stance'], stance_labels)
                loss_intent = self.criterion_intent(outputs['intent'], intent_labels)
                loss_harmfulness = self.criterion_harmfulness(outputs['harmfulness'], harmfulness_labels)
                loss_fairness = self.criterion_fairness(outputs['fairness'], fairness_labels)
                
                total_loss_batch = (loss_stance + 4.0 * loss_intent + 
                                  loss_harmfulness + loss_fairness)
                total_loss += total_loss_batch.item()
                
                # æ”¶é›†é¢„æµ‹ç»“æœ
                all_predictions['stance'].extend(torch.argmax(outputs['stance'], 1).cpu().numpy())
                all_labels['stance'].extend(stance_labels.cpu().numpy())
                
                all_predictions['harmfulness'].extend(torch.argmax(outputs['harmfulness'], 1).cpu().numpy())
                all_labels['harmfulness'].extend(harmfulness_labels.cpu().numpy())
                
                all_predictions['fairness'].extend(torch.argmax(outputs['fairness'], 1).cpu().numpy())
                all_labels['fairness'].extend(fairness_labels.cpu().numpy())
                
                # Intentå¤šæ ‡ç­¾åˆ†ç±» - ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
                intent_probs = torch.sigmoid(outputs['intent'])
                k = max(1, int(intent_labels.sum(dim=1).float().mean().item()))
                intent_preds = torch.zeros_like(intent_probs)
                for i in range(intent_probs.size(0)):
                    topk_indices = torch.topk(intent_probs[i], k).indices
                    intent_preds[i, topk_indices] = 1
                
                all_predictions['intent'].extend(intent_preds.cpu().numpy())
                all_labels['intent'].extend(intent_labels.cpu().numpy())
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = {}
        for task in ['stance', 'harmfulness', 'fairness']:
            if len(all_labels[task]) > 0:
                metrics[f'{task}_accuracy'] = accuracy_score(all_labels[task], all_predictions[task])
                metrics[f'{task}_f1'] = f1_score(all_labels[task], all_predictions[task], average='weighted')
            else:
                metrics[f'{task}_accuracy'] = 0.0
                metrics[f'{task}_f1'] = 0.0
        
        # Intentçš„å¤šæ ‡ç­¾æŒ‡æ ‡
        intent_metrics = safe_intent_metrics(all_predictions['intent'], all_labels['intent'])
        metrics['intent_exact_match'] = intent_metrics['exact_match']
        metrics['intent_macro_f1'] = intent_metrics['macro_f1']
        metrics['intent_micro_f1'] = intent_metrics['micro_f1']
        
        # æ¯ä¸ªintentæ ‡ç­¾çš„F1
        intent_labels_names = ['Political', 'Economic', 'Psychological', 'Public']
        for i, label in enumerate(intent_labels_names):
            metrics[f'intent_{label}_f1'] = intent_metrics['per_label_f1'][i] if i < len(intent_metrics['per_label_f1']) else 0.0
        
        avg_loss = total_loss / total_batches
        return avg_loss, metrics
        
    def train(self):
        """å®Œæ•´è®­ç»ƒè¿‡ç¨‹"""
        print("å¼€å§‹è®­ç»ƒ...")
        total_start_time = time.time()
        
        for epoch in range(self.num_epochs):
            print(f"\nEpoch {epoch+1}/{self.num_epochs}")
            print("-" * 50)
            
            train_loss, epoch_time = self.train_epoch(epoch + 1)
            val_loss, val_metrics = self.validate()
            
            self.scheduler.step()
            
            # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
            total_time = time.time() - total_start_time
            hours = int(total_time // 3600)
            minutes = int((total_time % 3600) // 60)
            
            print(f"\nEpoch {epoch+1} å®Œæˆ:")
            print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f}")
            print(f"  éªŒè¯æŸå¤±: {val_loss:.4f}")
            print(f"  Epochæ—¶é—´: {epoch_time/60:.1f}åˆ†é’Ÿ")
            print(f"  æ€»è®­ç»ƒæ—¶é—´: {hours}å°æ—¶{minutes}åˆ†é’Ÿ")
            print(f"  éªŒè¯æŒ‡æ ‡:")
            for metric, value in val_metrics.items():
                print(f"    {metric}: {value:.4f}")
            
            # æ—©åœæœºåˆ¶ - åŸºäºintent F1åˆ†æ•°
            current_intent_f1 = val_metrics['intent_macro_f1']
            if current_intent_f1 > self.best_intent_f1:
                self.best_intent_f1 = current_intent_f1
                torch.save(self.model.state_dict(), 'outputs/best_enhanced_dmint_model.pth')
                print("âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹! (åŸºäºintent F1)")
                self.counter = 0
            else:
                self.counter += 1
                if self.counter >= self.patience:
                    print(f"âš  æ—©åœ: {self.patience} ä¸ªepochæ„å›¾F1åˆ†æ•°æœªæå‡")
                    break
            
            print("=" * 60)

class TrainingValidator:
    """è®­ç»ƒéªŒè¯å™¨ - å…¨é¢æ£€æµ‹è®­ç»ƒæµç¨‹çš„æ¯ä¸ªç¯èŠ‚"""
    
    def __init__(self):
        self.results = {}
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def validate_data_loading(self):
        """éªŒè¯æ•°æ®åŠ è½½"""
        print("=" * 60)
        print("1. éªŒè¯æ•°æ®åŠ è½½")
        print("=" * 60)
        
        try:
            train_df, val_df, test_df = load_and_preprocess_data()
            
            if train_df is None or val_df is None or test_df is None:
                print("âœ— æ•°æ®åŠ è½½å¤±è´¥ - è¿”å›äº†None")
                return False
            
            print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ")
            print(f"  è®­ç»ƒé›†: {len(train_df)} æ ·æœ¬")
            print(f"  éªŒè¯é›†: {len(val_df)} æ ·æœ¬") 
            print(f"  æµ‹è¯•é›†: {len(test_df)} æ ·æœ¬")
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            required_columns = ['id', 'stance', 'intent', 'fairness', 'harmfulness', 'text']
            for df_name, df in [('è®­ç»ƒé›†', train_df), ('éªŒè¯é›†', val_df), ('æµ‹è¯•é›†', test_df)]:
                missing_columns = [col for col in required_columns if col not in df.columns]
                if missing_columns:
                    print(f"âœ— {df_name}ç¼ºå°‘åˆ—: {missing_columns}")
                    return False
            
            # æ£€æŸ¥æ ‡ç­¾æ•°æ®
            for df_name, df in [('è®­ç»ƒé›†', train_df), ('éªŒè¯é›†', val_df), ('æµ‹è¯•é›†', test_df)]:
                null_counts = df[['stance', 'intent', 'fairness', 'harmfulness']].isnull().sum()
                if null_counts.sum() > 0:
                    print(f"âœ— {df_name}æœ‰ç¼ºå¤±æ ‡ç­¾: {dict(null_counts)}")
                    return False
            
            # æ£€æŸ¥æ–‡æœ¬æ•°æ®
            for df_name, df in [('è®­ç»ƒé›†', train_df), ('éªŒè¯é›†', val_df), ('æµ‹è¯•é›†', test_df)]:
                text_lengths = df['text'].str.len()
                if text_lengths.min() == 0:
                    print(f"âœ— {df_name}æœ‰é›¶é•¿åº¦æ–‡æœ¬")
                    return False
                print(f"  {df_name}æ–‡æœ¬é•¿åº¦ - å¹³å‡: {text_lengths.mean():.1f}, æœ€å°: {text_lengths.min()}, æœ€å¤§: {text_lengths.max()}")
            
            self.results['dataframes'] = (train_df, val_df, test_df)
            return True
            
        except Exception as e:
            print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def validate_model_creation(self):
        """éªŒè¯æ¨¡å‹åˆ›å»º"""
        print("\n" + "=" * 60)
        print("2. éªŒè¯æ¨¡å‹åˆ›å»º")
        print("=" * 60)
        
        try:
            model_path = "C:/Users/LHTBS/Desktop/check919/models/chinese-roberta-wwm-ext"
            
            print("åŠ è½½tokenizerå’ŒBERTæ¨¡å‹...")
            tokenizer = BertTokenizer.from_pretrained(model_path)
            bert_model = BertModel.from_pretrained(model_path)
            
            print("åˆ›å»ºDMINTæ¨¡å‹...")
            model = EnhancedDMINTModel(bert_model)
            
            # æ£€æŸ¥æ¨¡å‹å‚æ•°
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            
            print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
            print(f"  æ€»å‚æ•°: {total_params:,}")
            print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
            print(f"  æ¨¡å‹ç»“æ„:")
            for name, module in model.named_children():
                num_params = sum(p.numel() for p in module.parameters())
                print(f"    {name}: {num_params:,} å‚æ•°")
            
            self.results['model'] = model
            self.results['tokenizer'] = tokenizer
            return True
            
        except Exception as e:
            print(f"âœ— æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def validate_data_processing(self):
        """éªŒè¯æ•°æ®å¤„ç†"""
        print("\n" + "=" * 60)
        print("3. éªŒè¯æ•°æ®å¤„ç†")
        print("=" * 60)
        
        try:
            if 'dataframes' not in self.results or 'tokenizer' not in self.results:
                print("âœ— éœ€è¦å…ˆå®Œæˆæ•°æ®åŠ è½½å’Œæ¨¡å‹åˆ›å»º")
                return False
            
            train_df, val_df, test_df = self.results['dataframes']
            tokenizer = self.results['tokenizer']
            
            # ä½¿ç”¨å°‘é‡æ•°æ®æµ‹è¯•
            mini_train_df = train_df.head(32)
            train_dataset = TextDataset(mini_train_df, tokenizer)
            train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
            
            print(f"âœ“ æ•°æ®å¤„ç†æˆåŠŸ")
            print(f"  æ•°æ®é›†å¤§å°: {len(train_dataset)}")
            print(f"  Batchæ•°é‡: {len(train_loader)}")
            
            # æ£€æŸ¥ä¸€ä¸ªbatchçš„æ•°æ®
            for batch in train_loader:
                print(f"  Batchæ•°æ®å½¢çŠ¶:")
                print(f"    input_ids: {batch['input_ids'].shape}")
                print(f"    attention_mask: {batch['attention_mask'].shape}")
                print(f"    stance: {batch['stance'].shape} (å€¼èŒƒå›´: {batch['stance'].min().item()}~{batch['stance'].max().item()})")
                print(f"    intent: {batch['intent'].shape} (å€¼èŒƒå›´: {batch['intent'].min().item():.2f}~{batch['intent'].max().item():.2f})")
                print(f"    fairness: {batch['fairness'].shape} (å€¼èŒƒå›´: {batch['fairness'].min().item()}~{batch['fairness'].max().item()})")
                print(f"    harmfulness: {batch['harmfulness'].shape} (å€¼èŒƒå›´: {batch['harmfulness'].min().item()}~{batch['harmfulness'].max().item()})")
                break
            
            self.results['train_loader'] = train_loader
            return True
            
        except Exception as e:
            print(f"âœ— æ•°æ®å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def validate_forward_pass(self):
        """éªŒè¯å‰å‘ä¼ æ’­"""
        print("\n" + "=" * 60)
        print("4. éªŒè¯å‰å‘ä¼ æ’­")
        print("=" * 60)
        
        try:
            if 'model' not in self.results or 'train_loader' not in self.results:
                print("âœ— éœ€è¦å…ˆå®Œæˆæ¨¡å‹åˆ›å»ºå’Œæ•°æ®å¤„ç†")
                return False
            
            model = self.results['model']
            train_loader = self.results['train_loader']
            
            model = model.to(self.device)
            model.eval()  # ä½¿ç”¨evalæ¨¡å¼é¿å…dropoutå½±å“
            
            for batch in train_loader:
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                
                with torch.no_grad():
                    outputs = model(input_ids, attention_mask)
                
                print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
                print(f"  è¾“å‡ºå½¢çŠ¶:")
                print(f"    stance: {outputs['stance'].shape}")
                print(f"    intent: {outputs['intent'].shape}")
                print(f"    fairness: {outputs['fairness'].shape}")
                print(f"    harmfulness: {outputs['harmfulness'].shape}")
                print(f"    gate_weights: {outputs['gate_weights'].shape}")
                
                # æ£€æŸ¥è¾“å‡ºå€¼èŒƒå›´
                print(f"  è¾“å‡ºå€¼èŒƒå›´:")
                print(f"    stance: {outputs['stance'].min().item():.4f} ~ {outputs['stance'].max().item():.4f}")
                print(f"    intent: {outputs['intent'].min().item():.4f} ~ {outputs['intent'].max().item():.4f}")
                print(f"    fairness: {outputs['fairness'].min().item():.4f} ~ {outputs['fairness'].max().item():.4f}")
                print(f"    harmfulness: {outputs['harmfulness'].min().item():.4f} ~ {outputs['harmfulness'].max().item():.4f}")
                print(f"    gate_weights: {outputs['gate_weights'].min().item():.4f} ~ {outputs['gate_weights'].max().item():.4f}")
                
                # æ£€æŸ¥gate_weightsæ˜¯å¦åˆç†ï¼ˆåº”è¯¥å’Œä¸º1ï¼‰
                gate_sums = outputs['gate_weights'].sum(dim=1)
                print(f"  gate_weightsæ¯è¡Œå’Œ: {gate_sums.min().item():.4f} ~ {gate_sums.max().item():.4f}")
                
                break
            
            self.results['model'] = model
            return True
            
        except Exception as e:
            print(f"âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def validate_loss_calculation(self):
        """éªŒè¯æŸå¤±è®¡ç®—"""
        print("\n" + "=" * 60)
        print("5. éªŒè¯æŸå¤±è®¡ç®—")
        print("=" * 60)
        
        try:
            if 'model' not in self.results or 'train_loader' not in self.results or 'dataframes' not in self.results:
                print("âœ— éœ€è¦å…ˆå®Œæˆå‰é¢çš„éªŒè¯æ­¥éª¤")
                return False
            
            train_df, _, _ = self.results['dataframes']
            model = self.results['model']
            train_loader = self.results['train_loader']
            
            # è®¡ç®—ç±»åˆ«æƒé‡
            intent_class_weights = compute_intent_class_weights(train_df)
            
            # åˆ›å»ºè®­ç»ƒå™¨ï¼ˆä½¿ç”¨train_loaderä½œä¸ºéªŒè¯é›†è¿›è¡Œæµ‹è¯•ï¼‰
            trainer = ImprovedDMINTTrainer(
                model, train_loader, train_loader, self.device,
                num_epochs=1,
                intent_class_weights=intent_class_weights
            )
            
            # æµ‹è¯•æŸå¤±è®¡ç®—
            model.train()  # åˆ‡æ¢å›è®­ç»ƒæ¨¡å¼
            
            for batch in train_loader:
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                stance_labels = batch['stance'].to(self.device)
                intent_labels = batch['intent'].to(self.device)
                harmfulness_labels = batch['harmfulness'].to(self.device)
                fairness_labels = batch['fairness'].to(self.device)
                
                outputs = model(input_ids, attention_mask)
                
                # è®¡ç®—å„ä¸ªä»»åŠ¡çš„æŸå¤±
                loss_stance = trainer.criterion_stance(outputs['stance'], stance_labels)
                loss_intent = trainer.criterion_intent(outputs['intent'], intent_labels)
                loss_harmfulness = trainer.criterion_harmfulness(outputs['harmfulness'], harmfulness_labels)
                loss_fairness = trainer.criterion_fairness(outputs['fairness'], fairness_labels)
                
                total_loss = (loss_stance + 4.0 * loss_intent + loss_harmfulness + loss_fairness)
                
                print(f"âœ“ æŸå¤±è®¡ç®—æˆåŠŸ")
                print(f"  å„ä»»åŠ¡æŸå¤±:")
                print(f"    stance: {loss_stance.item():.4f}")
                print(f"    intent: {loss_intent.item():.4f}")
                print(f"    harmfulness: {loss_harmfulness.item():.4f}")
                print(f"    fairness: {loss_fairness.item():.4f}")
                print(f"  æ€»æŸå¤±: {total_loss.item():.4f}")
                
                # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºæœ‰é™å€¼
                if not torch.isfinite(total_loss):
                    print(f"âœ— æŸå¤±å€¼ä¸ºéæœ‰é™å€¼: {total_loss.item()}")
                    return False
                
                break
            
            self.results['trainer'] = trainer
            return True
            
        except Exception as e:
            print(f"âœ— æŸå¤±è®¡ç®—å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def validate_backward_pass(self):
        """éªŒè¯åå‘ä¼ æ’­"""
        print("\n" + "=" * 60)
        print("6. éªŒè¯åå‘ä¼ æ’­")
        print("=" * 60)
        
        try:
            if 'model' not in self.results or 'train_loader' not in self.results or 'trainer' not in self.results:
                print("âœ— éœ€è¦å…ˆå®Œæˆå‰é¢çš„éªŒè¯æ­¥éª¤")
                return False
            
            model = self.results['model']
            train_loader = self.results['train_loader']
            trainer = self.results['trainer']
            
            model.train()
            trainer.optimizer.zero_grad()
            
            # æ‰§è¡Œä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒæ­¥éª¤
            for batch in train_loader:
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                stance_labels = batch['stance'].to(self.device)
                intent_labels = batch['intent'].to(self.device)
                harmfulness_labels = batch['harmfulness'].to(self.device)
                fairness_labels = batch['fairness'].to(self.device)
                
                outputs = model(input_ids, attention_mask)
                
                loss_stance = trainer.criterion_stance(outputs['stance'], stance_labels)
                loss_intent = trainer.criterion_intent(outputs['intent'], intent_labels)
                loss_harmfulness = trainer.criterion_harmfulness(outputs['harmfulness'], harmfulness_labels)
                loss_fairness = trainer.criterion_fairness(outputs['fairness'], fairness_labels)
                
                total_loss = (loss_stance + 4.0 * loss_intent + loss_harmfulness + loss_fairness)
                total_loss.backward()
                
                # æ£€æŸ¥æ¢¯åº¦
                has_gradients = False
                gradient_norms = []
                
                for name, param in model.named_parameters():
                    if param.grad is not None:
                        has_gradients = True
                        grad_norm = param.grad.norm().item()
                        gradient_norms.append(grad_norm)
                
                if has_gradients:
                    print(f"âœ“ åå‘ä¼ æ’­æˆåŠŸ")
                    print(f"  æ£€æµ‹åˆ°æ¢¯åº¦çš„å‚æ•°æ•°é‡: {len(gradient_norms)}")
                    print(f"  æ¢¯åº¦èŒƒæ•°èŒƒå›´: {min(gradient_norms):.6f} ~ {max(gradient_norms):.6f}")
                    
                    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦ä¸ºæœ‰é™å€¼
                    if not all(np.isfinite(grad_norm) for grad_norm in gradient_norms):
                        print(f"âœ— æ¢¯åº¦åŒ…å«éæœ‰é™å€¼")
                        return False
                else:
                    print(f"âœ— æœªæ£€æµ‹åˆ°æ¢¯åº¦")
                    return False
                
                # æ‰§è¡Œä¼˜åŒ–æ­¥éª¤
                trainer.optimizer.step()
                print(f"âœ“ ä¼˜åŒ–å™¨æ­¥éª¤å®Œæˆ")
                
                break
            
            return True
            
        except Exception as e:
            print(f"âœ— åå‘ä¼ æ’­å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def validate_training_loop(self):
        """éªŒè¯å®Œæ•´è®­ç»ƒå¾ªç¯"""
        print("\n" + "=" * 60)
        print("7. éªŒè¯å®Œæ•´è®­ç»ƒå¾ªç¯")
        print("=" * 60)
        
        try:
            if 'model' not in self.results or 'train_loader' not in self.results or 'trainer' not in self.results:
                print("âœ— éœ€è¦å…ˆå®Œæˆå‰é¢çš„éªŒè¯æ­¥éª¤")
                return False
            
            model = self.results['model']
            train_loader = self.results['train_loader']
            trainer = self.results['trainer']
            
            print("è¿è¡Œä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒepoch...")
            
            # è®°å½•åˆå§‹å‚æ•°
            initial_params = {}
            for name, param in model.named_parameters():
                if param.requires_grad:
                    initial_params[name] = param.data.clone()
            
            # è¿è¡Œä¸€ä¸ªè®­ç»ƒepoch
            train_loss, epoch_time = trainer.train_epoch(1)
            
            # æ£€æŸ¥å‚æ•°æ˜¯å¦æ›´æ–°
            params_updated = False
            for name, param in model.named_parameters():
                if param.requires_grad:
                    if not torch.equal(initial_params[name], param.data):
                        params_updated = True
                        break
            
            if params_updated:
                print(f"âœ“ è®­ç»ƒå¾ªç¯æˆåŠŸ")
                print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f}")
                print(f"  epochæ—¶é—´: {epoch_time:.2f}ç§’")
                print(f"  æ¨¡å‹å‚æ•°å·²æ›´æ–°")
            else:
                print(f"âš  è®­ç»ƒå®Œæˆä½†å‚æ•°æœªæ›´æ–°")
            
            return True
            
        except Exception as e:
            print(f"âœ— è®­ç»ƒå¾ªç¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def run_complete_validation(self):
        """è¿è¡Œå®Œæ•´éªŒè¯"""
        print("å¼€å§‹è®­ç»ƒæµç¨‹éªŒè¯...")
        print("=" * 60)
        
        validation_steps = [
            ("æ•°æ®åŠ è½½", self.validate_data_loading),
            ("æ¨¡å‹åˆ›å»º", self.validate_model_creation),
            ("æ•°æ®å¤„ç†", self.validate_data_processing),
            ("å‰å‘ä¼ æ’­", self.validate_forward_pass),
            ("æŸå¤±è®¡ç®—", self.validate_loss_calculation),
            ("åå‘ä¼ æ’­", self.validate_backward_pass),
            ("è®­ç»ƒå¾ªç¯", self.validate_training_loop),
        ]
        
        passed_steps = 0
        total_steps = len(validation_steps)
        
        for step_name, validation_func in validation_steps:
            try:
                success = validation_func()
                if success:
                    passed_steps += 1
                    print(f"âœ“ {step_name} - é€šè¿‡")
                else:
                    print(f"âœ— {step_name} - å¤±è´¥")
                    break
            except Exception as e:
                print(f"âœ— {step_name} - å¼‚å¸¸: {e}")
                break
        
        print("\n" + "=" * 60)
        print("éªŒè¯ç»“æœæ€»ç»“")
        print("=" * 60)
        print(f"é€šè¿‡æ­¥éª¤: {passed_steps}/{total_steps}")
        
        if passed_steps == total_steps:
            print("ğŸ‰ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼ä»£ç å¯ä»¥æ­£å¸¸è®­ç»ƒ")
            print("\nå»ºè®®ä¸‹ä¸€æ­¥:")
            print("1. è¿è¡Œå®Œæ•´è®­ç»ƒ")
            print("2. ç›‘æ§è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å’ŒæŒ‡æ ‡")
            print("3. æ£€æŸ¥éªŒè¯é›†æ€§èƒ½")
            return True
        else:
            print("âš  éƒ¨åˆ†éªŒè¯å¤±è´¥ï¼Œéœ€è¦ä¿®å¤é—®é¢˜")
            print(f"å¤±è´¥æ­¥éª¤: {validation_steps[passed_steps][0] if passed_steps < total_steps else 'N/A'}")
            return False

def main_training():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = "C:/Users/LHTBS/Desktop/check919/models/chinese-roberta-wwm-ext"
    
    try:
        # åŠ è½½tokenizerå’Œæ¨¡å‹
        print("åŠ è½½æ¨¡å‹...")
        tokenizer = BertTokenizer.from_pretrained(model_path)
        bert_model = BertModel.from_pretrained(model_path)
        print("æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # åŠ è½½æ•°æ®
        train_df, val_df, test_df = load_and_preprocess_data()
        
        # è®¡ç®—å¤šæ ‡ç­¾åˆ†ç±»çš„ç±»åˆ«æƒé‡
        intent_class_weights = compute_intent_class_weights(train_df)
        
        # åˆ›å»ºæ•°æ®é›†
        train_dataset = TextDataset(train_df, tokenizer)
        val_dataset = TextDataset(val_df, tokenizer)
        test_dataset = TextDataset(test_df, tokenizer)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä½¿ç”¨æ›´å¤§çš„batch size
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)
        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)
        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)
        
        print(f"è®­ç»ƒé›†batchæ•°é‡: {len(train_loader)}")
        print(f"éªŒè¯é›†batchæ•°é‡: {len(val_loader)}")
        print(f"æµ‹è¯•é›†batchæ•°é‡: {len(test_loader)}")
        
        # åˆ›å»ºå¢å¼ºç‰ˆDMINTæ¨¡å‹
        model = EnhancedDMINTModel(bert_model)
        model = model.to(device)
        print("å¢å¼ºç‰ˆDMINTæ¨¡å‹åˆ›å»ºæˆåŠŸ!")
        print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs('outputs', exist_ok=True)
        
        # è®­ç»ƒæ¨¡å‹ - ä½¿ç”¨ç±»åˆ«æƒé‡
        trainer = ImprovedDMINTTrainer(
            model, train_loader, val_loader, device, 
            num_epochs=5,
            intent_class_weights=intent_class_weights
        )
        trainer.train()
        
        # åŠ è½½æœ€ä½³æ¨¡å‹å¹¶æµ‹è¯•
        print("\nåŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•...")
        model.load_state_dict(torch.load('outputs/best_enhanced_dmint_model.pth'))
        
        # æµ‹è¯•æ¨¡å‹
        model.eval()
        test_predictions = {'stance': [], 'intent': [], 'harmfulness': [], 'fairness': []}
        test_labels = {'stance': [], 'intent': [], 'harmfulness': [], 'fairness': []}
        gate_weights = []  # æ”¶é›†é—¨æ§æƒé‡
        
        with torch.no_grad():
            for batch in test_loader:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                stance_labels = batch['stance'].to(device)
                intent_labels = batch['intent'].to(device)
                harmfulness_labels = batch['harmfulness'].to(device)
                fairness_labels = batch['fairness'].to(device)
                
                outputs = model(input_ids, attention_mask)
                
                test_predictions['stance'].extend(torch.argmax(outputs['stance'], 1).cpu().numpy())
                test_labels['stance'].extend(stance_labels.cpu().numpy())
                
                test_predictions['harmfulness'].extend(torch.argmax(outputs['harmfulness'], 1).cpu().numpy())
                test_labels['harmfulness'].extend(harmfulness_labels.cpu().numpy())
                
                test_predictions['fairness'].extend(torch.argmax(outputs['fairness'], 1).cpu().numpy())
                test_labels['fairness'].extend(fairness_labels.cpu().numpy())
                
                # Intentå¤šæ ‡ç­¾åˆ†ç±» - ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
                intent_probs = torch.sigmoid(outputs['intent'])
                k = max(1, int(intent_labels.sum(dim=1).float().mean().item()))
                intent_preds = torch.zeros_like(intent_probs)
                for i in range(intent_probs.size(0)):
                    topk_indices = torch.topk(intent_probs[i], k).indices
                    intent_preds[i, topk_indices] = 1
                
                test_predictions['intent'].extend(intent_preds.cpu().numpy())
                test_labels['intent'].extend(intent_labels.cpu().numpy())
                
                # æ”¶é›†é—¨æ§æƒé‡
                gate_weights.extend(outputs['gate_weights'].cpu().numpy())
        
        # åˆ†æé—¨æ§æƒé‡
        if len(gate_weights) > 0:
            gate_weights = np.array(gate_weights)
            avg_gate_weights = np.mean(gate_weights, axis=0)
            print(f"\nå¹³å‡é—¨æ§æƒé‡ - ä¿¡å¿µ: {avg_gate_weights[0]:.4f}, æ¬²æœ›: {avg_gate_weights[1]:.4f}, è®¡åˆ’: {avg_gate_weights[2]:.4f}")
        else:
            print("\næ²¡æœ‰æ”¶é›†åˆ°é—¨æ§æƒé‡")
        
        # è®¡ç®—æµ‹è¯•æŒ‡æ ‡
        print("\n" + "="*50)
        print("æµ‹è¯•é›†ç»“æœ:")
        print("="*50)
        
        for task in ['stance', 'harmfulness', 'fairness']:
            if len(test_labels[task]) > 0:
                acc = accuracy_score(test_labels[task], test_predictions[task])
                f1 = f1_score(test_labels[task], test_predictions[task], average='weighted')
                print(f"{task}: å‡†ç¡®ç‡={acc:.4f}, F1={f1:.4f}")
            else:
                print(f"{task}: æ²¡æœ‰æ•°æ®")
        
        # ä½¿ç”¨å®‰å…¨çš„intentæŒ‡æ ‡è®¡ç®—
        intent_metrics = safe_intent_metrics(test_predictions['intent'], test_labels['intent'])
        print(f"intent: ç²¾ç¡®åŒ¹é…={intent_metrics['exact_match']:.4f}, F1-macro={intent_metrics['macro_f1']:.4f}, F1-micro={intent_metrics['micro_f1']:.4f}")
        
        # ä¿å­˜ç»“æœ
        with open('outputs/enhanced_final_results.txt', 'w', encoding='utf-8') as f:
            f.write("å¢å¼ºç‰ˆDMINTæ¨¡å‹æœ€ç»ˆæµ‹è¯•ç»“æœ\n")
            f.write("="*50 + "\n")
            if len(gate_weights) > 0:
                f.write(f"å¹³å‡é—¨æ§æƒé‡ - ä¿¡å¿µ: {avg_gate_weights[0]:.4f}, æ¬²æœ›: {avg_gate_weights[1]:.4f}, è®¡åˆ’: {avg_gate_weights[2]:.4f}\n")
            for task in ['stance', 'harmfulness', 'fairness']:
                if len(test_labels[task]) > 0:
                    acc = accuracy_score(test_labels[task], test_predictions[task])
                    f1 = f1_score(test_labels[task], test_predictions[task], average='weighted')
                    f.write(f"{task}: å‡†ç¡®ç‡={acc:.4f}, F1={f1:.4f}\n")
            f.write(f"intent: ç²¾ç¡®åŒ¹é…={intent_metrics['exact_match']:.4f}, F1-macro={intent_metrics['macro_f1']:.4f}, F1-micro={intent_metrics['micro_f1']:.4f}\n")
        
        print("\nè®­ç»ƒå®Œæˆ! ç»“æœå·²ä¿å­˜åˆ° outputs/enhanced_final_results.txt")
        
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•° - æ•´åˆéªŒè¯å’Œè®­ç»ƒ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='DMINTæ¨¡å‹è®­ç»ƒä¸éªŒè¯')
    parser.add_argument('--mode', type=str, default='validate_and_train', 
                       choices=['validate', 'train', 'validate_and_train'],
                       help='è¿è¡Œæ¨¡å¼: validate(åªéªŒè¯), train(åªè®­ç»ƒ), validate_and_train(éªŒè¯å¹¶è®­ç»ƒ)')
    
    args = parser.parse_args()
    
    if args.mode == 'validate':
        # åªè¿è¡ŒéªŒè¯
        validator = TrainingValidator()
        success = validator.run_complete_validation()
        if success:
            print("\nğŸŠ éªŒè¯é€šè¿‡ï¼å¯ä»¥å®‰å…¨è¿›è¡Œè®­ç»ƒ")
        else:
            print("\nğŸ’¡ è¯·æ ¹æ®é”™è¯¯ä¿¡æ¯ä¿®å¤é—®é¢˜")
            
    elif args.mode == 'train':
        # åªè¿è¡Œè®­ç»ƒ
        print("ç›´æ¥å¼€å§‹è®­ç»ƒ...")
        main_training()
        
    elif args.mode == 'validate_and_train':
        # å…ˆéªŒè¯ï¼ŒéªŒè¯é€šè¿‡åè®­ç»ƒ
        print("å¼€å§‹éªŒè¯æµç¨‹...")
        validator = TrainingValidator()
        success = validator.run_complete_validation()
        
        if success:
            print("\nğŸ‰ éªŒè¯é€šè¿‡ï¼å¼€å§‹å®Œæ•´è®­ç»ƒ...")
            print("=" * 60)
            main_training()
        else:
            print("\nâŒ éªŒè¯å¤±è´¥ï¼Œè¯·å…ˆä¿®å¤é—®é¢˜å†è¿è¡Œè®­ç»ƒ")

if __name__ == "__main__":
    main()